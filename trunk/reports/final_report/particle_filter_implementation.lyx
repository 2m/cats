#LyX 1.6.5 created this file. For more info see http://www.lyx.org/
\lyxformat 345
\begin_document
\begin_header
\textclass IEEEtran
\use_default_options false
\language english
\inputencoding default
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\float_placement tbh
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_amsmath 0
\use_esint 0
\cite_engine basic
\use_bibtopic false
\paperorientation portrait
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\defskip medskip
\quotes_language english
\papercolumns 2
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\author "" 
\author "" 
\end_header

\begin_body

\begin_layout Subsection
Particle filter
\begin_inset Marginal
status open

\begin_layout Plain Layout
Needs more work
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Java simulation
\end_layout

\begin_layout Standard
Simulations in java where implemented only to weed out bugs.
 This approach was very successfull since the filter, when on the brick,
 worked as intended.
 The filter could also be profiled to find where optimizations would do
 most good.
 Even though profiling did give a better insigt on how the filter worked
 in practice the benefits were limited due to the vast differences of hardware
 between a PC and a NXT.
\end_layout

\begin_layout Subsubsection
Brick implementation
\end_layout

\begin_layout Standard
A problem with the particle filter approach was that it is very CPU intensive.
 It was clear from the beginning that some platform and problem specific
 optimizations would be needed.
\end_layout

\begin_layout Standard
A common approach to speeding up non-linear functions is look up tables.
 The up side of these is that they take little time to do.
 The only operations necessary is a rounding to the tables precision and
 then a look up in an array.
 The cons of this approach is that a lot of memory is needed to give the
 table accuracy.
 Since we did not know until very late in the implementation phase how much
 memory would be available, look up tables were not preferred.
\end_layout

\begin_layout Standard
The steps who needed optimizations badly
\begin_inset CommandInset citation
LatexCommand cite
key "MiodragBolic2004-11-12"

\end_inset

 where:
\end_layout

\begin_layout Enumerate
Some mathematical functions would be to slow on the NXT.
\end_layout

\begin_deeper
\begin_layout Enumerate
When comparing particles with sensor data one arc-tan operation is needed
 per particle (i.e.
 
\begin_inset Formula $\theta_{error}=\theta_{sighting}-arctan(\frac{y_{particle}-y_{est.position}}{x_{particle}-x_{est.position}})$
\end_inset

).
\end_layout

\begin_layout Enumerate
Criterion function is a Gaussian PDF (i.e.
 
\begin_inset Formula $w=C_{1}e^{C_{2}\theta_{error}^{2}}$
\end_inset

).
\end_layout

\end_deeper
\begin_layout Enumerate
Re-sampling needs one random sample per state variable and particle from
 a probability distribution in each iteration.
\end_layout

\begin_layout Enumerate
Floating point precision is not native to the NXT but implemented in fireware
\end_layout

\begin_layout Standard
Since the handling of floating point arithmetic is not native to the NXT,
 but emulated in the firmware
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
ref.
 forum?
\end_layout

\end_inset

, a classic approach to embedded mathematics was used, the so called fixed
 point arithmetic.
 Explain fixed point??
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
ref.
 Apple paper
\end_layout

\end_inset

.
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
12.20
\end_layout

\end_inset


\end_layout

\begin_layout Standard
For the first problem a short cut was investigated to replace the arc-tan
 and the exponential function.
 The data given are coordinates on a plane
\end_layout

\begin_layout Standard
\begin_inset Formula $u\cdot v=\frac{cos\theta}{\left\Vert u\right\Vert \left\Vert v\right\Vert }\Longrightarrow\theta=acos\left(\frac{u\cdot v}{\left\Vert u\right\Vert \left\Vert v\right\Vert }\right)$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $w=f_{weight}\left(\frac{v_{x}}{\left\Vert v\right\Vert }\right)$
\end_inset


\end_layout

\begin_layout Standard
lut of sine: small because of symmetry, in pos.
 case this could be even more optimized
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename images/particle_filter_java_penalty_function.eps
	lyxscale 50
	scale 50

\end_inset


\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:particle_weight_function"

\end_inset

Plot of the linearized weight function and analytical values of the same
 as reference
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
This method gave raise to the problem of square root operations needed to
 normalize vectors.
 The solution could be found in an old algorithm for taking the square root
 of integers 
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
ref.
 Internet
\end_layout

\end_inset

slightly modified to be used with fixed point arithmetic.
\end_layout

\begin_layout Standard
Re-sampling the particles is not a hard or heavy task but can still be improved
 significantly.
 Most of the time the particles are good and the number who really need
 to be re-sampled are small.
 If only the worst particles are resampled the filter would converge slower
 but would not need to do so much random sampling.??
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Is sorting needed elsewhere?
\end_layout

\end_inset


\end_layout

\end_body
\end_document
