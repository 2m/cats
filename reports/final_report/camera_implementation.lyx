#LyX 1.6.6.1 created this file. For more info see http://www.lyx.org/
\lyxformat 345
\begin_document
\begin_header
\textclass IEEEtran
\use_default_options false
\language english
\inputencoding default
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\float_placement tbh
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_amsmath 0
\use_esint 0
\cite_engine basic
\use_bibtopic false
\paperorientation portrait
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\defskip medskip
\quotes_language english
\papercolumns 2
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\author "" 
\author "" 
\end_header

\begin_body

\begin_layout Subsection
Camera
\end_layout

\begin_layout Subsubsection
Extracting angle measurements
\end_layout

\begin_layout Standard
To allow the mouse’s position to be calculated from angular measurements,
 the angles have to be given in a common coordinate system.
 We chose to use the fixed coordinate system of the arena.
 The sensor readings only provide relative angular values however, so the
 angles have to be converted.
 This is done using:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{equation}
\theta_{abs}=\theta_{cat}+\theta_{m}+\theta_{cam}\end{equation}

\end_inset

where 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none

\begin_inset Formula $\theta_{abs}$
\end_inset

 is the angle in the arena coordinate system, 
\begin_inset Formula $\theta_{cat}$
\end_inset

 is the angle of the cat (i.e.
 its orientation), 
\begin_inset Formula $\theta_{m}$
\end_inset

 is the angle of the camera motor relative to its starting position.
 Before program execution, the camera motor was always oriented so that
 the camera was facing straight forward in the same direction as that of
 the cat.
 The cats 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
were
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
 also oriented pointing towards 0
\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
° (along the x-axis) in the arena coordinate system, every time before
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
 program execution
\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
.
 That way we could use the assumed initial values of 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none

\begin_inset Formula $\theta_{cat}=0\text{°}$
\end_inset

 and 
\begin_inset Formula $\theta_{m}=0\text{°}$
\end_inset

.
 
\begin_inset Formula $\theta_{cam}$
\end_inset

 is the angle to the mouse (or landmark) relative to the camera's optical
 axis.
 This value has to be computed from the information available in the camera
 image containing the mouse.
 The mouse's horizontal pixel offset to the camera's optical axis can be
 converted to an angular reading.
 To investigate the relation between the pixel and the angular value, a
 simple test was performed.
 A set of markers was placed in the camera's entire field of view, with
 a fixed angle between each marker.
 Conveniently, the camera then rendered an image with a fixed horizontal
 pixel distance between each marker.
 Therefore, it was concluded that the following linear model to calculate
 the 
\begin_inset Formula $\theta_{cam}$
\end_inset

 would be used:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{equation}
\theta_{cam}=k(e+d)\end{equation}

\end_inset

where 
\begin_inset Formula $k$
\end_inset

 is a constant describing the horizontal angular span of one pixel, and
 
\begin_inset Formula $e$
\end_inset

 the pixel offset signal.
 The test showed that the camera's optical axis was not properly aligned
 with the center of the camera sensor, so a constant pixel offset 
\begin_inset Formula $d$
\end_inset

 was added to the model.
 This value had to be tweaked to each of the different cameras as they all
 showed different pixel offsets (up to 19
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
 pixels).
 The angular field of view of the camera was given in the specifications,
 and this value could also be verified in the test.
 Using this value 
\begin_inset Formula $a$
\end_inset

, 
\begin_inset Formula $k$
\end_inset

 could easily be calculated as
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{equation}
k=\frac{a}{p}\end{equation}

\end_inset

where 
\begin_inset Formula $p$
\end_inset

 is the number of pixels along the horizontal axis of the image.
\end_layout

\begin_layout Standard
Retrieving the horizontal pixel coordinates of the mouse marker in a camera
 image was easy since the LejOS API already has this feature implemented.
 Because the camera can detect up to eight targets with different colors,
 we chose to assign each landmark and the mouse with a unique color marker.
 That way, we can easily get the correct pixel locations of the mouse and
 the landmarks in the camera's field of view, even if several should appear
 at the same time.
\end_layout

\begin_layout Subsubsection
Modified camera firmware
\end_layout

\begin_layout Standard
While observing the camera output using the NXTCamView software we have
 noticed that tracked object is often split into two, four or even more
 parts.
 This effect can be seen even more significantly when lighting conditions
 are poor.
 The issue could be solved by taking into consideration all tracked objects
 and calculating median coordinates.
 This would have effectively introduced some overhead to the camera regulator
 code.
 We chose to modify camera firmware so that it does not split tracked objects
 or rather merges them before transmitting data to robot.
 We have found modified camera firmware called 
\begin_inset Quotes eld
\end_inset

MergeBlob
\begin_inset Quotes erd
\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "MergeBlob"

\end_inset

 which does exactly that.
 We have also tweaked the minimum and maximum size of the tracked objects.
\end_layout

\begin_layout Standard
Since we have started to modify camera's firmware we thought that it is
 good idea to put some more filtering logic to the camera so we can keep
 camera's AVR processor busy, offloading the NXT's CPU.
 We have added tracking object filtering by the Y coordinate 
\begin_inset CommandInset citation
LatexCommand cite
key "MergeBlobPatch"

\end_inset

.
 So objects which are lower than certain minimum and higher then certain
 maximum are not tracked.
 This is true since we know the height of the mouse and the height of the
 landmarks.
 This helped us to remove any unnecessary noise such as windows and other
 artificial light sources which could be mistakenly tracked.
\end_layout

\begin_layout Subsubsection
PD tracking-regulator
\end_layout

\begin_layout Standard
We needed a regulator that would follow the movement of the mouse as good
 as possible to allow for fast mouse movement.
 Also, the regulator needed to be smart enough not to keep spinning the
 motor in one direction.
 Doing so resulted in that the camera cable got tangled up, thereby stopping
 the motor and hindering any further movement in that direction.
 The solution was implementing a lower and higher bound of the rotation
 of the camera.
 The bounds were chosen as [-180°, 180°] (relative to the starting position
 of the camera motor), to allow a 360° field of view.
 Whenever the camera motor tried to go outside this bound, the direction
 of the motor changed.
\end_layout

\begin_layout Standard
When designing a regulator of this kind an error signal is necessary.
 Since it is desirable to keep the mouse in the middle of the camera image
 (only horizontal position regarded), the error was chosen to be the pixel
 difference between the mouse's location in the image and the image center
 (corrected with an offset, i.e.
 
\begin_inset Formula $e+d$
\end_inset

 above).
 This error signal limited in resolution by the resolution of the camera
 and it is bounded by the field of view of the camera.
 If the mouse disappears outside of the picture, the error signal is set
 to the same as the bound value on the side of the picture of which the
 mouse was last seen.
 Also, a control signal is necessary.
 The natural choice of the speed and direction of the motor, was chosen.
\end_layout

\begin_layout Standard
First a simple proportional regulator was tested.
 It performed quite well, but became a bit oscillatory at high speeds, i.e.
 at large values of the P-parameter.
 Then a PID-controller was implemented, which yielded smoother and better
 performance.
 The integrating part was later dropped since it did not contribute to the
 performance, giving the final PD-controller.
\end_layout

\end_body
\end_document
